%autosave 0


import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from adam_acquire import get_titanic





df = get_titanic()
df.head()


df.shape


df.info()

# we can identify null values in the data


df.describe().head()





col_mask = df.dtypes == 'object'
col_mask

# i'm gonna say that is an object im just going to look at the count
# any numbers we will look by histograms


df.columns[col_mask]


for col in df.columns[col_mask]:

    print(df[col].value_counts())
    print('\n\n\n')

# we noticed some reduntant information int he dataset


num_mask = df.dtypes != 'object'
num_mask





for col in df.columns[num_mask]:

    plt.figure()
    plt.title(f'Distribution of {col}')
    plt.hist(df[col])


df.isna()


df.isna().sum() # brief statement tells me how many nulls i have and in which column


round(df.isna().sum() /len(df) * 100, 2)





df.head()


df = df.drop(columns = ['passenger_id', 'pclass', 'embarked'])
df.head()





seed = 42

train, val_test = train_test_split(df, train_size = 0.7,
                                   random_state = seed,
                                   stratify = df.survived)

val, test = train_test_split(val_test, train_size = 0.5,
                             random_state = seed,
                             stratify = val_test.survived)

# a common split percentage 70%, 15%, 15%


train.survived.value_counts(normalize = True)


val.survived.value_counts(normalize = True)





test.survived.value_counts(normalize = True)


# Stratify has dsitributed the different percentage of teh split data equally when we normalize each group.





train.isna().sum()


train.embark_town.value_counts()


train.embark_town = train.embark_town.fillna('Southampton')
train.embark_town.isna().sum()


train[train.age.isna()].head(10)


train.age.describe()
#mean can be swayed by a greater degree by the outlier than the median


imputer = SimpleImputer(strategy='median')


# added an extra brackets to 
# add a list to another list create an extra dimension
imputer.fit(train[['age']])

#imputer has been fit into the age column, an now is ready to impute transform .


train.age = imputer.transform(train[['age']])
train.age.isna().sum()


val.age.isna().sum()


val.age = imputer.transform(val[['age']])
val.age.isna().sum()


train.age.value_counts(dropna=False)





#this function will be good for splitting classification data per our target

def train_val_test(df, strat, seed = 42):

    train, val_test = train_test_split(df, train_size = 0.7,
                                       random_state = seed,
                                       stratify = df[strat])

    val, test = train_test_split(val_test, train_size = 0.5,
                                 random_state = seed,
                                 stratify = val_test[strat])

    return train, val, test


ftrain, fval, ftest = train_val_test(df, 'survived')


ftrain.head()


train.head()
