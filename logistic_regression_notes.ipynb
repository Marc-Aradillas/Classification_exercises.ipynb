{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9be2970-0205-4198-8657-62b8b7ef7a6b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29fe87b-87fb-446e-855f-b53e38660c01",
   "metadata": {},
   "source": [
    "What is Logistic Regression?\n",
    "\n",
    "Technically a regression algorithm (goal is to find the values for the coefficients that weight each input variable)\n",
    "\n",
    "Used for predicting discrete outcomes (binomial and multinomial)\n",
    "\n",
    "Because the prediction for the output is transformed using the logistic function, a non-linear function, it is a classification algorithm.\n",
    "\n",
    "The output is a value between 0 and 1 that represents the probability of one class over the other.\n",
    "\n",
    "Like linear regression, logistic regression works better when you remove attributes that are either unrelated to the output variable or correlated to other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe3d12-1674-4f6d-8c7a-c3055c20f21c",
   "metadata": {},
   "source": [
    "- Pros\n",
    "\n",
    "    High interpretabability. It's explainable to others, i.e. it's useful for understanding the influence of several independent variables on a single outcome variable.\n",
    "    \n",
    "    We can choose to ‘snap’ predictions to 0 and 1 via a rule (such as if < .5, 0 else 1) OR we can choose to use the output as is, which is a probability of being class 1.\n",
    "    \n",
    "    It’s a fast model and is a good place to start with a benchmark for comparing with other classification algorithms.\n",
    "    \n",
    "    Very efficient and does not require many computational resources. Runs fast.\n",
    "    \n",
    "    Outputs clear predicted probabilities.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "- Cons\n",
    "\n",
    "    Assumes all predictors are independent of each other.\n",
    "    \n",
    "    Missing values must be dealt with prior to fitting the model.\n",
    "    \n",
    "    We can’t solve non-linear problems with logistic regression since it’s decision surface is linear.\n",
    "    \n",
    "    Not always as accurate as other classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed98f98c-b85b-4276-8c71-2c798885a480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  versicolor  virginica\n",
       "1           5.1          3.5           1.4          0.2           0          0\n",
       "2           4.9          3.0           1.4          0.2           0          0\n",
       "3           4.7          3.2           1.3          0.2           0          0\n",
       "4           4.6          3.1           1.5          0.2           0          0\n",
       "5           5.0          3.6           1.4          0.2           0          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "# read Iris data from pydatset\n",
    "df = data('iris')\n",
    "\n",
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "# we will have 2 different target variables \n",
    "dummies = pd.get_dummies(df['species'], drop_first=True)\n",
    "\n",
    "df = pd.concat([df, dummies], axis=1).drop(columns=['species'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febdb55e-4af0-48f8-91c0-6261203abbc1",
   "metadata": {},
   "source": [
    "## Train Validate Test\n",
    "\n",
    "**Now we'll do our train/validate/test split:**\n",
    "\n",
    "We will walk through the lesson aiming to predict versicolor.\n",
    "    \n",
    "We'll do exploration and train our model on the train data\n",
    "    \n",
    "We tune our model on validate, since it will be out-of-sample until we use it.\n",
    "    \n",
    "And keep the test nice and safe and separate, for our final out-of-sample dataset, to see how well our tuned model performs on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab770ee-eb41-41f8-acf8-93426642848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a635dbf-a39e-40a9-bd13-424dc0469a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='versicolor', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['versicolor','virginica'])\n",
    "y_train = train.versicolor\n",
    "\n",
    "X_validate = validate.drop(columns=['versicolor','virginica'])\n",
    "y_validate = validate.versicolor\n",
    "\n",
    "X_test = test.drop(columns=['versicolor','virginica'])\n",
    "y_test = test.versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451c953-72c1-44fb-9b26-951228c3fd83",
   "metadata": {},
   "source": [
    "## Documentation:\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "- penalty: str, 'l1' or 'l2', default: 'l2', Used to specify the norm used in the penalization. The 'newton-cg', 'sag' and 'lbfgs' solvers support only l2 penalties. We will discuss l1 & l2 penalties & regularization\n",
    "\n",
    "- C: float, default: 1.0, Inverse of regularization strength; must be a positive float.\n",
    "\n",
    "- class_weight: dict or 'balanced', default: None, Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. The \"balanced\" mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)). Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.\n",
    "\n",
    "- random_state: set the seed for reproducibility.\n",
    "\n",
    "- intercept_scaling: float, default 1. Useful only when the solver 'liblinear' is used and self.fit_intercept is set to True and you have not already scaled your data.\n",
    "\n",
    "- solver: {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default: 'liblinear', but will change to 'lbfgs' in v 0.22. The solver is the algorithm to use in the optimization problem. For small datasets, 'liblinear' is a good choice, whereas 'sag' and 'saga' are faster for large ones. For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs' handle multinomial loss; 'liblinear' is limited to one-versus-rest schemes. 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas 'liblinear' and 'saga' handle L1 penalty. If using sag and saga solvers, make sure the features are on a similar scale.\n",
    "\n",
    "- max_iter: int, default: 100, Useful only for the newton-cg, sag and lbfgs solvers, Maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "- multi_class: I recommend using other algorithms for multiclass or one-vs-rest if you want to use logistic regression. options: {'ovr', 'multinomial', 'auto'}, default: 'ovr' (one-versus-rest). If the option chosen is 'ovr', then a binary problem is fit for each label. For 'multinomial' the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. 'multinomial' is unavailable when solver='liblinear'. 'auto' selects 'ovr' if the data is binary, or if solver='liblinear', and otherwise selects 'multinomial'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e605ff-17f0-41d2-9cf7-86e8e6a6f11c",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "**For the first model, we will set the solver to be lbfgs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ca52e-5578-4e59-8beb-7d431f7a900e",
   "metadata": {},
   "source": [
    "### Make the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f567778-c1b4-49b3-a4b9-0a12ec023856",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Create the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c01d20-cdda-40c4-9f79-795bd89ededc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={0:1, 1:99}, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4b0d7a-ba27-4cbe-b9f1-8e67be19e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={0:1, 1:99}, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dbb4a-4b24-4450-99ba-1c07e442c683",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Fit the logistic regression algorithm to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711e77fa-f541-451f-97e4-6a2162caa02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, class_weight={0: 1, 1: 99}, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight={0: 1, 1: 99}, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, class_weight={0: 1, 1: 99}, random_state=123)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e24648-7527-4d54-acda-90ed3715563e",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Evaluate importance, or weight, of each feature, using the coefficients.\n",
    "\n",
    "Evaluate the intercept of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d8f91b-d096-4536-999c-319cd3788e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.45745489 -4.33000304  2.00440881 -2.79033335]]\n",
      "Intercept: \n",
      " [14.54733857]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55166ad-7674-4b2b-8eb9-7a29194b5f58",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Estimate whether or not the species is versicolor for each observation, using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3e1ae4-dea0-468d-8d08-188bcd964849",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f1f65b-6264-4845-9e68-da120b2d925f",
   "metadata": {},
   "source": [
    "## Estimate Probability\n",
    "\n",
    "Estimate the probability of species being versicolor for each observation, using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e12d9d16-51b9-49c1-ac03-4cbf53a22b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bfcce-1609-47e7-b7eb-1669d0cc3ffb",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Compute the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afdafe95-c344-44fe-9885-768c03c7645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.55\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0afd2-ac82-42e9-9568-931ecef3b809",
   "metadata": {},
   "source": [
    "Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c04d2ad-99e4-47e4-ae96-4b02cd83ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 38]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab34293-703f-4da3-acb5-459d67341807",
   "metadata": {},
   "source": [
    "Create a classificaiton report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b7378b-b8d9-4fbb-8e19-e6ed74d1774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.32      0.49        56\n",
      "           1       0.42      1.00      0.60        28\n",
      "\n",
      "    accuracy                           0.55        84\n",
      "   macro avg       0.71      0.66      0.54        84\n",
      "weighted avg       0.81      0.55      0.52        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a01ea0-20fc-437f-833e-01a47e62c7bf",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "We can create new models by changing features we feed the algorithm, hyperparameters, and/or the alogrithm itself. For this second model, we will adjust our hyperparameter, C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b016c9c-ed5d-42b4-b81e-c5a2259d07a3",
   "metadata": {},
   "source": [
    "### Make the Model\n",
    "\n",
    "create the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8047ab-ac22-462c-933c-e3da0398c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2 = LogisticRegression(C=.1, class_weight={0:1, 1:99}, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e50010-bb88-4333-8529-32f86fb48904",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Fit the logistic regression algorithm to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8717698-f291-4bba-9915-bae53b2d7ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, class_weight={0: 1, 1: 99}, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight={0: 1, 1: 99}, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, class_weight={0: 1, 1: 99}, random_state=123)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df120e-4509-401e-ade7-cfab85b117e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Importance\n",
    "\n",
    "Evaluate importance, or weight, of each feature, using the coefficients.\n",
    "\n",
    "Evaluate the intercept of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b3dbb2-cbe4-49fe-98c5-b12cebff5582",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.45745489 -4.33000304  2.00440881 -2.79033335]]\n",
      "Intercept: \n",
      " [14.54733857]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31e984-e5a1-484b-8365-4563628c1e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
